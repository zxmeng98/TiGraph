(tigraph) (base) yezhisheng@n122-228-066:~/tigraph$ torchrun --nnodes 1 --nproc_per_node 4 --master_port 2923 revgnn_pp_trainonall_sync_data.py --dataset ogbn-arxiv --num_layers 112 --pid 619891
W0408 11:22:35.028000 139955130782720 torch/distributed/run.py:779] 
W0408 11:22:35.028000 139955130782720 torch/distributed/run.py:779] *****************************************
W0408 11:22:35.028000 139955130782720 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0408 11:22:35.028000 139955130782720 torch/distributed/run.py:779] *****************************************
> initializing torch distributed ...
ogbn-arxiv load and processed successfully
Train nodes: 90941, Val nodes: 29799, Test nodes: 48603
Num of train batches: 1, num of train microbatches: 2, microbatch size: 84670
stage=1 layers=28 - 56
stage=0 layers=0 - 28
stage=2 layers=56 - 84
stage=3 layers=84 - 112
Training...
Epoch 00000 | Loss 3.8823 | Epoch Time 8.66s
Epoch 00001 | Loss 3.2861 | Epoch Time 4.04s
Epoch 00002 | Loss 3.2166 | Epoch Time 3.50s
Epoch 00003 | Loss 3.1576 | Epoch Time 3.43s
Epoch 00004 | Loss 3.1303 | Epoch Time 3.49s
Epoch 00005 | Loss 3.1184 | Epoch Time 3.45s
Epoch 00006 | Loss 3.1123 | Epoch Time 3.49s
Epoch 00007 | Loss 3.1077 | Epoch Time 3.44s
Epoch 00008 | Loss 3.1042 | Epoch Time 3.48s
Loading trained LM features (title and abstract) ...
LM_emb_path: ./lm_workloads/prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed0.emb
Null embeddings found, override with gold embeddings.
Epoch 00009 | Loss 3.1020 | Epoch Time 3.30s
Epoch 00010 | Loss 3.1001 | Epoch Time 3.46s
Epoch 00011 | Loss 3.0986 | Epoch Time 3.46s
Epoch 00012 | Loss 3.0987 | Epoch Time 3.44s
Epoch 00013 | Loss 3.0972 | Epoch Time 3.46s
Epoch 00014 | Loss 3.0953 | Epoch Time 3.46s
Epoch 00015 | Loss 3.0929 | Epoch Time 3.44s
Epoch 00016 | Loss 3.0913 | Epoch Time 3.45s
Epoch 00017 | Loss 3.0893 | Epoch Time 3.45s
Epoch 00018 | Loss 3.0859 | Epoch Time 3.44s
Loading trained LM features (title and abstract) ...
LM_emb_path: ./lm_workloads/prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed0.emb
Null embeddings found, override with gold embeddings.
Epoch 00019 | Loss 3.0831 | Epoch Time 3.33s
Epoch 00020 | Loss 3.0791 | Epoch Time 3.45s
Epoch 00021 | Loss 3.0729 | Epoch Time 3.44s
Epoch 00022 | Loss 3.0647 | Epoch Time 3.45s
Epoch 00023 | Loss 3.0562 | Epoch Time 3.48s
Epoch 00024 | Loss 3.0423 | Epoch Time 3.44s
Epoch 00025 | Loss 3.0257 | Epoch Time 3.44s
Epoch 00026 | Loss 3.0039 | Epoch Time 3.45s
Epoch 00027 | Loss 2.9782 | Epoch Time 3.44s
Epoch 00028 | Loss 2.9454 | Epoch Time 3.44s
Loading trained LM features (title and abstract) ...
LM_emb_path: ./lm_workloads/prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed0.emb
Null embeddings found, override with gold embeddings.
Epoch 00029 | Loss 2.9088 | Epoch Time 3.32s
Epoch 00030 | Loss 2.8702 | Epoch Time 3.44s
Epoch 00031 | Loss 2.8313 | Epoch Time 3.44s
Epoch 00032 | Loss 2.8004 | Epoch Time 3.45s
Epoch 00033 | Loss 2.7598 | Epoch Time 3.43s
Epoch 00034 | Loss 2.7228 | Epoch Time 3.47s
Epoch 00035 | Loss 2.6862 | Epoch Time 3.46s
Epoch 00036 | Loss 2.6531 | Epoch Time 3.44s
Epoch 00037 | Loss 2.6267 | Epoch Time 3.45s
Epoch 00038 | Loss 2.6001 | Epoch Time 3.44s
Loading trained LM features (title and abstract) ...
LM_emb_path: ./lm_workloads/prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed0.emb
Null embeddings found, override with gold embeddings.
Epoch 00039 | Loss 2.5725 | Epoch Time 3.33s
Epoch 00040 | Loss 2.5649 | Epoch Time 3.44s
Epoch 00041 | Loss 2.5349 | Epoch Time 3.44s